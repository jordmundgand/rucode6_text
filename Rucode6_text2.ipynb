{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XPUN5vLqBQFE"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузка train, public_test, privat_test и тензора весов модели\n",
        "!gdown 1hp4ln3vHYaBkeVquHdgu_QA5JZkQWFTP\n",
        "!gdown 1SSzUoJI6AsS1mUFCp-Zdb0s13ZZJMNDl\n",
        "!gdown 1gjQApadBmv4YjuZgv-L7FwpUyRV4LchO\n",
        "!gdown 1TgoNl5WkRockrJXZGdJWTbb4Ibqq8at-"
      ],
      "metadata": {
        "id": "2DOU-9-PQZbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# загружаем входные данные !пропишите правильные пути файлов\n",
        "train=pd.read_csv('/content/drive/MyDrive/RuCode6_2/train.csv')\n",
        "test=pd.read_csv('/content/drive/MyDrive/RuCode6_2/public_test.csv')\n",
        "testp=pd.read_csv('/content/drive/MyDrive/RuCode6_2/private_test.csv')"
      ],
      "metadata": {
        "id": "3eA4dUy8B-Qk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаём словарь символов\n",
        "voc=list(CountVectorizer(lowercase=False, token_pattern= r\"(?u)\\b\\w\\w+\\b\", ngram_range=(1, 1), \n",
        "                         analyzer=\"char\").fit(train['corrupted_text'].tolist()+train['correct_text'].tolist()).vocabulary_.keys())"
      ],
      "metadata": {
        "id": "xPj10VqECC9l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# задаём слой посимвольной текстовой векторизации\n",
        "tv=tf.keras.layers.TextVectorization(max_tokens=len(voc)+2, \n",
        "                                  standardize=None, split='character', \n",
        "                                  output_mode='int', output_sequence_length=59, pad_to_max_tokens=True, vocabulary=voc)"
      ],
      "metadata": {
        "id": "F_qchx9CCC5_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# кодируем target в sparse\n",
        "y=tv(tf.constant(train['correct_text'].values)).numpy()"
      ],
      "metadata": {
        "id": "pzfJRqmSCC2u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(train[['corrupted_text']],\n",
        "                                             y,\n",
        "                                             test_size=0.1,\n",
        "                                             random_state=0)"
      ],
      "metadata": {
        "id": "8dIemIgfCCzj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# модель: гибридная нейронная сеть из двух веток: резидуальная двунаправленная LSTM и свёрточная (по архитектуре близкая к U-net)\n",
        "# конкатенируются и обрабатываются верхним слоем однонаправленной LSTM\n",
        "\n",
        "inp=tf.keras.Input(shape=(1),dtype='string',name='inp') \n",
        "\n",
        "lay1__0=tv(inp)\n",
        "\n",
        "lay2_0__0=tf.one_hot(lay1__0,depth=250)\n",
        "lay2_1__0=tf.roll(lay2_0__0, shift=-1, axis=-2)\n",
        "lay2_2__0=tf.roll(lay2_0__0, shift=1, axis=-2)\n",
        "\n",
        "lay2__0=tf.keras.layers.Concatenate()([lay2_0__0,lay2_1__0,lay2_2__0])\n",
        "\n",
        "\n",
        "lay3_1__0=tf.keras.layers.LSTM(256,kernel_initializer='glorot_uniform', return_sequences=True,go_backwards=False)(lay2__0)\n",
        "lay3_2__0=tf.keras.layers.LSTM(256,kernel_initializer='glorot_uniform',return_sequences=True,go_backwards=True)(lay2__0)\n",
        "lay3__0=tf.keras.layers.Concatenate()([lay3_1__0,lay3_2__0,lay2__0])\n",
        "\n",
        "lay4_1__0=tf.keras.layers.LSTM(1024,kernel_initializer='glorot_uniform',return_sequences=True,go_backwards=False)(lay3__0)\n",
        "lay4_2__0=tf.keras.layers.LSTM(1024,kernel_initializer='glorot_uniform',return_sequences=True,go_backwards=True)(lay3__0)\n",
        "\n",
        "\n",
        "lay1__1=tf.keras.layers.TextVectorization(max_tokens=len(voc)+2, \n",
        "                                  standardize=None, split='character', \n",
        "                                  output_mode='int', output_sequence_length=64, pad_to_max_tokens=True, vocabulary=voc)(inp)\n",
        "lay2__1=tf.one_hot(lay1__1,depth=250)\n",
        "lay3__1=tf.keras.layers.Conv1D(256, 3, padding='same', activation='tanh')(lay2__1)\n",
        "\n",
        "lay4__1=tf.keras.layers.MaxPool1D(2)(lay3__1)\n",
        "\n",
        "lay5__1=tf.keras.layers.Conv1D(256, 3, padding='same', activation='tanh')(lay4__1)\n",
        "\n",
        "lay6__1=tf.keras.layers.MaxPool1D(2)(lay5__1)\n",
        "\n",
        "lay7__1=tf.keras.layers.Conv1D(256, 3, padding='same', activation='tanh')(lay6__1)\n",
        "\n",
        "lay8__1=tf.keras.layers.MaxPool1D(2)(lay7__1)\n",
        "\n",
        "lay9__1=tf.keras.layers.Flatten()(lay8__1)\n",
        "\n",
        "lay11__1=tf.keras.layers.Dense(256*8, activation='tanh')(lay9__1)\n",
        "\n",
        "lay12__1=tf.keras.layers.Reshape((8, 256))(lay11__1)\n",
        "lay12_1__1=tf.keras.layers.Concatenate()([lay12__1,lay8__1])\n",
        "\n",
        "lay13__1=tf.keras.layers.Conv1DTranspose(256, 2, strides=2, activation='tanh')(lay12_1__1)\n",
        "lay13_1__1=tf.keras.layers.Concatenate()([lay13__1,lay6__1])\n",
        "\n",
        "lay14__1=tf.keras.layers.Conv1DTranspose(256, 2, strides=2, activation='tanh')(lay13_1__1)\n",
        "lay14_1__1=tf.keras.layers.Concatenate()([lay14__1,lay4__1])\n",
        "\n",
        "lay15__1=tf.keras.layers.Conv1DTranspose(250, 2, strides=2, activation='tanh')(lay14_1__1)\n",
        "\n",
        "lay16__1=lay15__1[:,:59,:]\n",
        "\n",
        "\n",
        "lay4__0=tf.keras.layers.Concatenate()([lay4_1__0,lay4_2__0,lay3__0,lay2__0,lay16__1])\n",
        "\n",
        "lay5=tf.keras.layers.LSTM(250,kernel_initializer='glorot_uniform', \n",
        "                          activation='softmax', return_sequences=True)(lay4__0)\n",
        "\n",
        "model = tf.keras.Model(inputs=inp,outputs=lay5)\n",
        "optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001), \n",
        "              loss=\"sparse_categorical_crossentropy\", \n",
        "              metrics=\"sparse_categorical_accuracy\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq8U7Mu6C4TE",
        "outputId": "740b20d6-684d-4758-ca37-b6e31ef434a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inp (InputLayer)               [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " text_vectorization_1 (TextVect  (None, 64)          0           ['inp[0][0]']                    \n",
            " orization)                                                                                       \n",
            "                                                                                                  \n",
            " tf.one_hot_1 (TFOpLambda)      (None, 64, 250)      0           ['text_vectorization_1[0][0]']   \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 64, 256)      192256      ['tf.one_hot_1[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 32, 256)      0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 32, 256)      196864      ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 16, 256)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 16, 256)      196864      ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 8, 256)      0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2048)         4196352     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 8, 256)       0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " text_vectorization (TextVector  (None, 59)          0           ['inp[0][0]']                    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 8, 512)       0           ['reshape[0][0]',                \n",
            "                                                                  'max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " tf.one_hot (TFOpLambda)        (None, 59, 250)      0           ['text_vectorization[0][0]']     \n",
            "                                                                                                  \n",
            " conv1d_transpose (Conv1DTransp  (None, 16, 256)     262400      ['concatenate_2[0][0]']          \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " tf.roll (TFOpLambda)           (None, 59, 250)      0           ['tf.one_hot[0][0]']             \n",
            "                                                                                                  \n",
            " tf.roll_1 (TFOpLambda)         (None, 59, 250)      0           ['tf.one_hot[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 16, 512)      0           ['conv1d_transpose[0][0]',       \n",
            "                                                                  'max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 59, 750)      0           ['tf.one_hot[0][0]',             \n",
            "                                                                  'tf.roll[0][0]',                \n",
            "                                                                  'tf.roll_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_transpose_1 (Conv1DTran  (None, 32, 256)     262400      ['concatenate_3[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 59, 256)      1031168     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 59, 256)      1031168     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 32, 512)      0           ['conv1d_transpose_1[0][0]',     \n",
            "                                                                  'max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 59, 1262)     0           ['lstm[0][0]',                   \n",
            "                                                                  'lstm_1[0][0]',                 \n",
            "                                                                  'concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_transpose_2 (Conv1DTran  (None, 64, 250)     256250      ['concatenate_4[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 59, 1024)     9367552     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 59, 1024)     9367552     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 59, 250)     0           ['conv1d_transpose_2[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 59, 4310)     0           ['lstm_2[0][0]',                 \n",
            "                                                                  'lstm_3[0][0]',                 \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  (None, 59, 250)      4561000     ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 30,921,826\n",
            "Trainable params: 30,921,826\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# предварительное обучение, для оценки точности и кривой обучения на отложенной выборке\n",
        "history=model.fit(X_train[['corrupted_text']].astype('str').values, \n",
        "                  y_train, batch_size=1024,epochs=10, \n",
        "        validation_data=(X_val[['corrupted_text']].astype('str').values,\n",
        "                         y_val))"
      ],
      "metadata": {
        "id": "zCDud0L_C4PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# дообучение на всех данных\n",
        "history=model.fit(train[['corrupted_text']].astype('str').values, \n",
        "                  y, batch_size=1024,epochs=40)"
      ],
      "metadata": {
        "id": "nZd09BZ7C4Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cmMUyKZ-D7sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# предварительное предсказание на паблик тесте\n",
        "ansd1=np.argmax(model.predict(test[['corrupted_text']].astype('str').values[:50000],batch_size=1024),axis=-1)\n",
        "ansd2=np.argmax(model.predict(test[['corrupted_text']].astype('str').values[50000:100000],batch_size=1024),axis=-1)\n",
        "ansd3=np.argmax(model.predict(test[['corrupted_text']].astype('str').values[100000:150000],batch_size=1024),axis=-1)\n",
        "ansd4=np.argmax(model.predict(test[['corrupted_text']].astype('str').values[150000:],batch_size=1024),axis=-1)\n",
        "ansl=[]\n",
        "for cnt in np.vstack((ansd1,ansd2,ansd3,ansd4)):\n",
        "  ansl.append(''.join(list(map(lambda x: tvvoc[x], cnt.tolist()))))\n",
        "test['correct_text']=ansl"
      ],
      "metadata": {
        "id": "o-xv-AiJD62d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# оценка точности предварительного предсказания на паблик тесте\n",
        "ansd1=np.argmax(model.predict(test[['correct_text']].astype('str').values[:50000],batch_size=1024),axis=-1)\n",
        "ansd2=np.argmax(model.predict(test[['correct_text']].astype('str').values[50000:100000],batch_size=1024),axis=-1)\n",
        "ansd3=np.argmax(model.predict(test[['correct_text']].astype('str').values[100000:150000],batch_size=1024),axis=-1)\n",
        "ansd4=np.argmax(model.predict(test[['correct_text']].astype('str').values[150000:],batch_size=1024),axis=-1)\n",
        "ansl=[]\n",
        "for cnt in np.vstack((ansd1,ansd2,ansd3,ansd4)):\n",
        "  ansl.append(''.join(list(map(lambda x: tvvoc[x], cnt.tolist()))))\n",
        "test['correct_text2']=ansl"
      ],
      "metadata": {
        "id": "wuMEb54gD6ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# фильтрация условно точных предсказаний\n",
        "test['tag1']=1*(test['correct_text']==test['correct_text2'])"
      ],
      "metadata": {
        "id": "BMC1pMECD6ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# благодаря сверточной ветке модель хорошо может дообучаться на тестовых данных (примерно +5% от начальной accuracy)\n",
        "# дообучение на условно точных предсказаниях на паблик тесте\n",
        "X_train,y_train=test[['corrupted_text']][test['tag1']==1],tv(tf.constant(test['correct_text'].values[test['tag1']==1])).numpy()\n",
        "history=model.fit(X_train,y_train,batch_size=1024,epochs=5)"
      ],
      "metadata": {
        "id": "nSgd_A1RD6gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5YqjNMOD6cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузка весов после обучения на паблик тесте \n",
        "model.load_weights('/content/drive/MyDrive/RuCode6_2/rucode_text6.h5')"
      ],
      "metadata": {
        "id": "ALe0EH5GIM8Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qY_YSlKdIM1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# предварительное предсказание и дообучение на приват тесте\n",
        "ansd1=np.argmax(model.predict(testp[['corrupted_text']].astype('str').values[:50000],batch_size=1024),axis=-1)\n",
        "ansd2=np.argmax(model.predict(testp[['corrupted_text']].astype('str').values[50000:],batch_size=1024),axis=-1)\n",
        "ansl=[]\n",
        "for cnt in np.vstack((ansd1,ansd2)):\n",
        "  ansl.append(''.join(list(map(lambda x: tvvoc[x], cnt.tolist()))))\n",
        "testp['correct_text']=ansl\n",
        "ansd1=np.argmax(model.predict(testp[['correct_text']].astype('str').values[:50000],batch_size=1024),axis=-1)\n",
        "ansd2=np.argmax(model.predict(testp[['correct_text']].astype('str').values[50000:],batch_size=1024),axis=-1)\n",
        "ansl=[]\n",
        "for cnt in np.vstack((ansd1,ansd2)):\n",
        "  ansl.append(''.join(list(map(lambda x: tvvoc[x], cnt.tolist()))))\n",
        "testp['correct_text2']=ansl\n",
        "testp['tag1']=1*(testp['correct_text']==testp['correct_text2'])\n",
        "X_train,y_train=testp[['corrupted_text']][testp['tag1']==1],tv(tf.constant(testp['correct_text'].values[testp['tag1']==1])).numpy()\n",
        "history=model.fit(X_train,y_train,batch_size=512,epochs=5)"
      ],
      "metadata": {
        "id": "8rdzhcGXFes0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7fNkg0F1Feo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# предварительное конечное предсказание на приват тесте\n",
        "ansd1=np.argmax(model.predict(testp[['corrupted_text']].astype('str').values[:50000],batch_size=1024),axis=-1)\n",
        "ansd2=np.argmax(model.predict(testp[['corrupted_text']].astype('str').values[50000:],batch_size=1024),axis=-1)\n",
        "ansl=[]\n",
        "for cnt in np.vstack((ansd1,ansd2)):\n",
        "  ansl.append(''.join(list(map(lambda x: tvvoc[x], cnt.tolist()))))\n",
        "testp['correct_text3']=ansl"
      ],
      "metadata": {
        "id": "3SAKcuj3Fekf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# конечное предсказание на приват тесте (если модель прогнать по данным дважды точность возрастает примерно на 2%, благодаря тому что модели сложно исправить два слова за один проход)\n",
        "ansd1=np.argmax(model.predict(testp[['correct_text3']].astype('str').values[:50000],batch_size=1024),axis=-1)\n",
        "ansd2=np.argmax(model.predict(testp[['correct_text3']].astype('str').values[50000:],batch_size=1024),axis=-1) \n",
        "ansl=[]\n",
        "for cnt in np.vstack((ansd1,ansd2)):\n",
        "  ansl.append(''.join(list(map(lambda x: tvvoc[x], cnt.tolist()))))\n",
        "testp['correct_text4']=ansl"
      ],
      "metadata": {
        "id": "8E6xDCEWFeg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сохранение результата\n",
        "testp['correct_text4'].to_csv('subr2p.csv',header=False,index=False)"
      ],
      "metadata": {
        "id": "lE3gynAvGm0t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}